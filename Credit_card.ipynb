{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING PACKAGES\n",
    "\n",
    "import pandas as pd # data processing\n",
    "import numpy as np # working with arrays\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "from termcolor import colored as cl # text customization\n",
    "import itertools # advanced tools\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # data normalization\n",
    "from sklearn.model_selection import train_test_split # data split\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision tree algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN algorithm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix # evaluation metric\n",
    "from sklearn.metrics import accuracy_score # evaluation metric\n",
    "from sklearn.metrics import f1_score # evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
      "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
      "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
      "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
      "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
      "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
      "\n",
      "        V25       V26       V27       V28  Amount  Class  \n",
      "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING DATA\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df.drop('Time', axis = 1, inplace = True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCASE COUNT\u001b[0m\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n",
      "\u001b[1mTotal number of cases are 284807\u001b[0m\n",
      "\u001b[1mNumber of Non-fraud cases are 284315\u001b[0m\n",
      "\u001b[1mNumber of Non-fraud cases are 492\u001b[0m\n",
      "\u001b[1mPercentage of fraud cases is 0.17\u001b[0m\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cases = len(df)\n",
    "nonfraud_count = len(df[df.Class == 0])\n",
    "fraud_count = len(df[df.Class == 1])\n",
    "fraud_percentage = round(fraud_count/nonfraud_count*100, 2)\n",
    "\n",
    "print(cl('CASE COUNT', attrs = ['bold']))\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Total number of cases are {}'.format(cases), attrs = ['bold']))\n",
    "print(cl('Number of Non-fraud cases are {}'.format(nonfraud_count), attrs = ['bold']))\n",
    "print(cl('Number of Non-fraud cases are {}'.format(fraud_count), attrs = ['bold']))\n",
    "print(cl('Percentage of fraud cases is {}'.format(fraud_percentage), attrs = ['bold']))\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCASE AMOUNT STATISTICS\u001b[0m\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n",
      "\u001b[1mNON-FRAUD CASE AMOUNT STATS\u001b[0m\n",
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n",
      "\u001b[1mFRAUD CASE AMOUNT STATS\u001b[0m\n",
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nonfraud_cases = df[df.Class == 0]\n",
    "fraud_cases = df[df.Class == 1]\n",
    "\n",
    "print(cl('CASE AMOUNT STATISTICS', attrs = ['bold']))\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))\n",
    "print(cl('NON-FRAUD CASE AMOUNT STATS', attrs = ['bold']))\n",
    "print(nonfraud_cases.Amount.describe())\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))\n",
    "print(cl('FRAUD CASE AMOUNT STATS', attrs = ['bold']))\n",
    "print(fraud_cases.Amount.describe())\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m0    0.244964\n",
      "1   -0.342475\n",
      "2    1.160686\n",
      "3    0.140534\n",
      "4   -0.073403\n",
      "5   -0.338556\n",
      "6   -0.333279\n",
      "7   -0.190107\n",
      "8    0.019392\n",
      "9   -0.338516\n",
      "Name: Amount, dtype: float64\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "amount = df['Amount'].values\n",
    "\n",
    "df['Amount'] = sc.fit_transform(amount.reshape(-1, 1))\n",
    "\n",
    "print(cl(df['Amount'].head(10), attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mX_train samples : \u001b[0m [[-1.11504743  1.03558276  0.80071244 -1.06039825  0.03262117  0.85342216\n",
      "  -0.61424348 -3.23116112  1.53994798 -0.81690879 -1.30559201  0.1081772\n",
      "  -0.85960958 -0.07193421  0.90665563 -1.72092961  0.79785322 -0.0067594\n",
      "   1.95677806 -0.64489556  3.02038533 -0.53961798  0.03315649 -0.77494577\n",
      "   0.10586781 -0.43085348  0.22973694 -0.0705913  -0.30145418]]\n",
      "\u001b[1mX_test samples : \u001b[0m [[-0.32333357  1.05745525 -0.04834115 -0.60720431  1.25982115 -0.09176072\n",
      "   1.1591015  -0.12433461 -0.17463954 -1.64440065 -1.11886302  0.20264731\n",
      "   1.14596495 -1.80235956 -0.24717793 -0.06094535  0.84660574  0.37945439\n",
      "   0.84726224  0.18640942 -0.20709827 -0.43389027 -0.26161328 -0.04665061\n",
      "   0.2115123   0.00829721  0.10849443  0.16113917 -0.19330595]]\n",
      "\u001b[1my_train samples : \u001b[0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1my_test samples : \u001b[0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# DATA SPLIT\n",
    "\n",
    "X = df.drop('Class', axis = 1).values\n",
    "y = df['Class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(cl('X_train samples : ', attrs = ['bold']), X_train[:1])\n",
    "print(cl('X_test samples : ', attrs = ['bold']), X_test[0:1])\n",
    "print(cl('y_train samples : ', attrs = ['bold']), y_train[0:20])\n",
    "print(cl('y_test samples : ', attrs = ['bold']), y_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELING\n",
    "\n",
    "# 1. Decision Tree\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_yhat = tree_model.predict(X_test)\n",
    "\n",
    "# 2. K-Nearest Neighbors\n",
    "\n",
    "n = 5\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = n)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_yhat = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n",
      "Train: [ 30473  30496  31002 ... 284804 284805 284806] Test: [    0     1     2 ... 57017 57018 57019]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [ 30473  30496  31002 ... 113964 113965 113966]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [ 81609  82400  83053 ... 170946 170947 170948]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [150654 150660 150661 ... 227866 227867 227868]\n",
      "Train: [     0      1      2 ... 227866 227867 227868] Test: [212516 212644 213092 ... 284804 284805 284806]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.99827076 0.00172924]\n",
      "[0.99827952 0.00172048]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mACCURACY SCORE\u001b[0m\n",
      "\u001b[1m------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0c00a51f939c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ACCURACY SCORE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'------------------------------------------------------------------------'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy score of the Decision Tree model is {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_yhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'------------------------------------------------------------------------'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy score of the KNN model is {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_yhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Accuracy score\n",
    "\n",
    "print(cl('ACCURACY SCORE', attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, tree_yhat)), attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Accuracy score of the KNN model is {}'.format(accuracy_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)), attrs = ['bold'], color = 'red'))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Accuracy score of the SVM model is {}'.format(accuracy_score(y_test, svm_yhat)), attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Accuracy score of the Random Forest Tree model is {}'.format(accuracy_score(y_test, rf_yhat)), attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99491</th>\n",
       "      <td>67146.0</td>\n",
       "      <td>-0.984677</td>\n",
       "      <td>0.568697</td>\n",
       "      <td>0.135391</td>\n",
       "      <td>-4.016034</td>\n",
       "      <td>0.406649</td>\n",
       "      <td>-0.509106</td>\n",
       "      <td>0.479542</td>\n",
       "      <td>0.486028</td>\n",
       "      <td>1.634792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158616</td>\n",
       "      <td>-0.301181</td>\n",
       "      <td>-0.307951</td>\n",
       "      <td>-1.334014</td>\n",
       "      <td>0.442110</td>\n",
       "      <td>-1.109293</td>\n",
       "      <td>0.262984</td>\n",
       "      <td>0.097393</td>\n",
       "      <td>5.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111690</th>\n",
       "      <td>72327.0</td>\n",
       "      <td>-4.198735</td>\n",
       "      <td>0.194121</td>\n",
       "      <td>-3.917586</td>\n",
       "      <td>3.920748</td>\n",
       "      <td>-1.875486</td>\n",
       "      <td>-2.118933</td>\n",
       "      <td>-3.614445</td>\n",
       "      <td>1.687884</td>\n",
       "      <td>-2.189871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801312</td>\n",
       "      <td>-0.183001</td>\n",
       "      <td>-0.440387</td>\n",
       "      <td>0.292539</td>\n",
       "      <td>-0.144967</td>\n",
       "      <td>-0.251744</td>\n",
       "      <td>1.249414</td>\n",
       "      <td>-0.131525</td>\n",
       "      <td>238.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85624</th>\n",
       "      <td>60858.0</td>\n",
       "      <td>1.222698</td>\n",
       "      <td>0.287407</td>\n",
       "      <td>0.419745</td>\n",
       "      <td>0.782182</td>\n",
       "      <td>-0.608585</td>\n",
       "      <td>-1.277310</td>\n",
       "      <td>0.045237</td>\n",
       "      <td>-0.179678</td>\n",
       "      <td>0.133185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272418</td>\n",
       "      <td>-0.839536</td>\n",
       "      <td>0.174842</td>\n",
       "      <td>0.649408</td>\n",
       "      <td>0.143076</td>\n",
       "      <td>0.076391</td>\n",
       "      <td>-0.028967</td>\n",
       "      <td>0.033279</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64460</th>\n",
       "      <td>51155.0</td>\n",
       "      <td>-11.205461</td>\n",
       "      <td>7.914633</td>\n",
       "      <td>-13.987752</td>\n",
       "      <td>4.333341</td>\n",
       "      <td>-8.484970</td>\n",
       "      <td>-3.506561</td>\n",
       "      <td>-8.935243</td>\n",
       "      <td>7.704449</td>\n",
       "      <td>-2.336584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942593</td>\n",
       "      <td>-0.987848</td>\n",
       "      <td>-0.279446</td>\n",
       "      <td>-0.027299</td>\n",
       "      <td>0.644344</td>\n",
       "      <td>-0.263078</td>\n",
       "      <td>1.084023</td>\n",
       "      <td>0.211933</td>\n",
       "      <td>99.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41569</th>\n",
       "      <td>40742.0</td>\n",
       "      <td>-2.377533</td>\n",
       "      <td>0.520539</td>\n",
       "      <td>-8.094139</td>\n",
       "      <td>8.005351</td>\n",
       "      <td>2.640750</td>\n",
       "      <td>-3.381586</td>\n",
       "      <td>-1.934372</td>\n",
       "      <td>0.562322</td>\n",
       "      <td>-3.104027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148284</td>\n",
       "      <td>0.721100</td>\n",
       "      <td>2.661291</td>\n",
       "      <td>-0.508620</td>\n",
       "      <td>-0.401657</td>\n",
       "      <td>0.587611</td>\n",
       "      <td>0.500326</td>\n",
       "      <td>0.551760</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time         V1        V2         V3        V4        V5        V6  \\\n",
       "99491   67146.0  -0.984677  0.568697   0.135391 -4.016034  0.406649 -0.509106   \n",
       "111690  72327.0  -4.198735  0.194121  -3.917586  3.920748 -1.875486 -2.118933   \n",
       "85624   60858.0   1.222698  0.287407   0.419745  0.782182 -0.608585 -1.277310   \n",
       "64460   51155.0 -11.205461  7.914633 -13.987752  4.333341 -8.484970 -3.506561   \n",
       "41569   40742.0  -2.377533  0.520539  -8.094139  8.005351  2.640750 -3.381586   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "99491   0.479542  0.486028  1.634792  ... -0.158616 -0.301181 -0.307951   \n",
       "111690 -3.614445  1.687884 -2.189871  ...  0.801312 -0.183001 -0.440387   \n",
       "85624   0.045237 -0.179678  0.133185  ... -0.272418 -0.839536  0.174842   \n",
       "64460  -8.935243  7.704449 -2.336584  ...  0.942593 -0.987848 -0.279446   \n",
       "41569  -1.934372  0.562322 -3.104027  ...  0.148284  0.721100  2.661291   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "99491  -1.334014  0.442110 -1.109293  0.262984  0.097393    5.89      0  \n",
       "111690  0.292539 -0.144967 -0.251744  1.249414 -0.131525  238.90      1  \n",
       "85624   0.649408  0.143076  0.076391 -0.028967  0.033279    6.99      0  \n",
       "64460  -0.027299  0.644344 -0.263078  1.084023  0.211933   99.99      1  \n",
       "41569  -0.508620 -0.401657  0.587611  0.500326  0.551760    1.00      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
    "\n",
    "# Lets shuffle the data before creating the subsamples\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling before cross validating (prone to overfit)\n",
    "X = new_df.drop('Class', axis=1)\n",
    "y = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data is already scaled we should split our training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This is explicitly used for undersampling.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the values into an array for feeding the classification algorithms.\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement simple classifiers\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression Has a training score of 93.0 % accuracy score\n",
      "Classifiers:  KNeighborsClassifier Has a training score of 64.0 % accuracy score\n",
      "Classifiers:  SVC Has a training score of 54.0 % accuracy score\n",
      "Classifiers:  DecisionTreeClassifier Has a training score of 93.0 % accuracy score\n"
     ]
    }
   ],
   "source": [
    "# Wow our scores are getting even high scores even when applying cross validation.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GridSearchCV to find the best parameters.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Logistic Regression \n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "\n",
    "\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "# We automatically get the logistic regression with the best parameters.\n",
    "log_reg = grid_log_reg.best_estimator_\n",
    "\n",
    "knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\n",
    "grid_knears.fit(X_train, y_train)\n",
    "# KNears best estimator\n",
    "knears_neighbors = grid_knears.best_estimator_\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "grid_svc = GridSearchCV(SVC(), svc_params)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "# SVC best estimator\n",
    "svc = grid_svc.best_estimator_\n",
    "\n",
    "# DecisionTree Classifier\n",
    "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "              \"min_samples_leaf\": list(range(5,7,1))}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# tree best estimator\n",
    "tree_clf = grid_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross Validation Score:  94.02%\n",
      "Knears Neighbors Cross Validation Score 67.22%\n",
      "Support Vector Classifier Cross Validation Score 92.25%\n",
      "DecisionTree Classifier Cross Validation Score 93.26%\n"
     ]
    }
   ],
   "source": [
    "log_reg_score = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "print('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n",
    "\n",
    "\n",
    "knears_score = cross_val_score(knears_neighbors, X_train, y_train, cv=5)\n",
    "print('Knears Neighbors Cross Validation Score', round(knears_score.mean() * 100, 2).astype(str) + '%')\n",
    "\n",
    "svc_score = cross_val_score(svc, X_train, y_train, cv=5)\n",
    "print('Support Vector Classifier Cross Validation Score', round(svc_score.mean() * 100, 2).astype(str) + '%')\n",
    "\n",
    "tree_score = cross_val_score(tree_clf, X_train, y_train, cv=5)\n",
    "print('DecisionTree Classifier Cross Validation Score', round(tree_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 56960  56961  56962 ... 284804 284805 284806] Test: [    0     1     2 ... 56959 58005 58604]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [ 56960  56961  56962 ... 113924 113925 113926]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [111734 111761 113227 ... 170886 170887 170888]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [167481 167885 167962 ... 227849 227850 227851]\n",
      "Train: [     0      1      2 ... 227849 227850 227851] Test: [225504 225734 226380 ... 284804 284805 284806]\n"
     ]
    }
   ],
   "source": [
    "# We will undersample during cross validating\n",
    "undersample_X = df.drop('Class', axis=1)\n",
    "undersample_y = df['Class']\n",
    "\n",
    "for train_index, test_index in sss.split(undersample_X, undersample_y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n",
    "    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n",
    "    \n",
    "undersample_Xtrain = undersample_Xtrain.values\n",
    "undersample_Xtest = undersample_Xtest.values\n",
    "undersample_ytrain = undersample_ytrain.values\n",
    "undersample_ytest = undersample_ytest.values \n",
    "\n",
    "undersample_accuracy = []\n",
    "undersample_precision = []\n",
    "undersample_recall = []\n",
    "undersample_f1 = []\n",
    "undersample_auc = []\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Plot LogisticRegression Learning Curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator1, estimator2, estimator3, estimator4, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(20,14), sharey=True)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    # First Estimator\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"#ff9124\")\n",
    "    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
    "    ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
    "             label=\"Training score\")\n",
    "    ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
    "             label=\"Cross-validation score\")\n",
    "    ax1.set_title(\"Logistic Regression Learning Curve\", fontsize=14)\n",
    "    ax1.set_xlabel('Training size (m)')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc=\"best\")\n",
    "    \n",
    "    # Second Estimator \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator2, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    ax2.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"#ff9124\")\n",
    "    ax2.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
    "    ax2.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
    "             label=\"Training score\")\n",
    "    ax2.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
    "             label=\"Cross-validation score\")\n",
    "    ax2.set_title(\"Knears Neighbors Learning Curve\", fontsize=14)\n",
    "    ax2.set_xlabel('Training size (m)')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend(loc=\"best\")\n",
    "    \n",
    "    # Third Estimator\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator3, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    ax3.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"#ff9124\")\n",
    "    ax3.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
    "    ax3.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
    "             label=\"Training score\")\n",
    "    ax3.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
    "             label=\"Cross-validation score\")\n",
    "    ax3.set_title(\"Support Vector Classifier \\n Learning Curve\", fontsize=14)\n",
    "    ax3.set_xlabel('Training size (m)')\n",
    "    ax3.set_ylabel('Score')\n",
    "    ax3.grid(True)\n",
    "    ax3.legend(loc=\"best\")\n",
    "    \n",
    "    # Fourth Estimator\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator4, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    ax4.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"#ff9124\")\n",
    "    ax4.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
    "    ax4.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
    "             label=\"Training score\")\n",
    "    ax4.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
    "             label=\"Cross-validation score\")\n",
    "    ax4.set_title(\"Decision Tree Classifier \\n Learning Curve\", fontsize=14)\n",
    "    ax4.set_xlabel('Training size (m)')\n",
    "    ax4.set_ylabel('Score')\n",
    "    ax4.grid(True)\n",
    "    ax4.legend(loc=\"best\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ShuffleSplit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-94fa1a47e126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_learning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknears_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.87\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ShuffleSplit' is not defined"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "plot_learning_curve(log_reg, knears_neighbors, svc, tree_clf, X_train, y_train, (0.87, 1.01), cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
